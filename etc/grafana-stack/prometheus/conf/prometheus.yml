global:
  scrape_interval: 15s
  scrape_timeout: 10s
  scrape_protocols:
  - OpenMetricsText1.0.0
  - OpenMetricsText0.0.1
  - PrometheusText0.0.4
  evaluation_interval: 15s
alerting:
  alertmanagers:
  - follow_redirects: true
    enable_http2: true
    scheme: http
    timeout: 10s
    api_version: v2
    static_configs:
    - targets: []
scrape_configs:
- job_name: prometheus
  honor_timestamps: true
  track_timestamps_staleness: false
  scrape_interval: 15s
  scrape_timeout: 10s
  scrape_protocols:
  - OpenMetricsText1.0.0
  - OpenMetricsText0.0.1
  - PrometheusText0.0.4
  metrics_path: /metrics
  scheme: http
  enable_compression: true
  follow_redirects: true
  enable_http2: true
  static_configs:
  - targets:
    - localhost:9090

# Basically add a prometheus.port=... label to the docker compose service and it
# should start getting scraped.
- job_name: "docker-services"
  docker_sd_configs:
    - host: unix:///var/run/docker.sock # You can also use http/https to connect to the Docker daemon.
  relabel_configs:
    # Only keep containers that have a `prometheus-job` label.
    - source_labels: [__meta_docker_container_label_prometheus_port]
      regex: .+
      action: keep
    - source_labels: ['__meta_docker_container_label_com_docker_compose_service']
      target_label: 'service'
    - source_labels: ['__meta_docker_container_label_com_docker_compose_project']
      target_label: 'project'
    - source_labels:
      - __address__
      - __meta_docker_container_label_prometheus_port
      target_label: __address__
      regex: '(.*):(\d+);(\d+)'
      replacement: "${1}:${3}"


